
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Scraping Web Pages With Scrapy - Michael Herman</title>
  <meta name="author" content="Michael Herman">

  
  <meta name="description" content="This is a simple tutorial on how to write a crawler using Scrapy to scrape and parse Craigslist Nonprofit jobs in San Francisco and store the data to &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mherman.org/blog/2012/11/05/scraping-web-pages-with-scrapy">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Michael Herman" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Fjalla+One" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
<!--- MathJax Configuration -->
<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-37074204-1', 'auto');
    ga('send', 'pageview');

  </script>



</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">Michael Herman</a></h1>
  
    <h2>Software Developer</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscribe" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS" target="_blank"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="25" height="25" viewbox="0 0 100 100"><path class="social" d="M 13.310204,73.332654 C 5.967347,73.332654 0,79.322448 0,86.621428 c 0,7.338776 5.967347,13.262246 13.310204,13.262246 7.370408,0 13.328572,-5.92245 13.328572,-13.262246 0,-7.29898 -5.958164,-13.288774 -13.328572,-13.288774 z M 0.01530612,33.978572 V 53.143878 C 12.493878,53.143878 24.229592,58.02347 33.068368,66.865306 41.894898,75.685714 46.767346,87.47449 46.767346,100 h 19.25 C 66.017346,63.592858 36.4,33.979592 0.01530612,33.978572 l 0,0 z M 0.03877552,0 V 19.17449 C 44.54796,19.17551 80.77551,55.437756 80.77551,100 H 100 C 100,44.87653 55.15102,0 0.03877552,0 z"></path></svg></a></li>
  
</ul>
  
  
  
  
  
  
  
  
  
  
    
      <form action="http://google.com/search" method="get">
        <fieldset role="search">
          <input type="hidden" name="sitesearch" value="mherman.org" />
    
          <input class="search" type="text" name="q" results="0" placeholder="Search"/>
        </fieldset>
      </form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      
        <h1 class="entry-title">Scraping Web Pages With Scrapy</h1>
      
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2012-11-05T14:59:00-07:00'><span class='date'><span class='date-month'>Nov</span> <span class='date-day'>5</span><span class='date-suffix'>th</span>, <span class='date-year'>2012</span></span> <span class='time'>2:59 pm</span></time>
        
        
      </p>
    
  </header>


<div class="entry-content"><p><strong>This is a simple tutorial on how to write a crawler using <a href="http://scrapy.org/">Scrapy</a> to scrape and parse Craigslist Nonprofit jobs in San Francisco and store the data to a CSV file.</strong></p>

<p>If you don&rsquo;t have any experience with Scrapy, start by reading this <a href="http://doc.scrapy.org/en/0.16/intro/tutorial.html">tutorial</a>. Also, I assume that you are familiar with Xpath; if not, please read the Xpath basic <a href="http://w3schools.com/xpath/">tutorial</a> on w3schools. Enjoy!</p>

<p><strong>Updates:</strong>
- 09/18/2015 â€“ Updated the Scrapy scripts</p>

<blockquote><p>Be sure to check out the accompanying <a href="http://www.youtube.com/watch?v=1EFnX1UkXVU">video</a>!</p></blockquote>

<h2>Installation</h2>

<p>Start by <a href="http://scrapy.org/">downloading</a> and installing Scrapy (v0.16.5) and all its dependencies. Refer to this <a href="http://www.youtube.com/watch?v=eEK2kmmvIdw">video</a>, if you need help.</p>

<h2>Create a Project</h2>

<p>Once installed, open your terminal and create a Scrapy project by navigating to the directory you&rsquo;d like to store your project in and then running the following command:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="err">$</span> <span class="n">scrapy</span> <span class="n">startproject</span> <span class="n">craigslist_sample</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Item Class:</strong> Open the <em>items.py</em> file within the &ldquo;craigslist_sample&rdquo; directory. Edit the file to define the fields that you want contained within the <code>Item</code>. Since we want the post title and subsequent URL, the <code>Item</code> class looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span><span class="p">,</span> <span class="n">Field</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">CraigslistSampleItem</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
</span><span class='line'>    <span class="n">title</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span><span class='line'>    <span class="n">link</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>The Spider:</strong> The spider defines the initial URL (<a href="http://sfbay.craigslist.org/npo/">http://sfbay.craigslist.org/npo/</a>), how to follow links/pagination (if necessary), and how to extract and parse the fields defined above. The spider must define these attributes:</p>

<ul>
<li><em>name</em>: the spider&rsquo;s unique identifier</li>
<li><em>start_urls</em>: URLs the spider begins crawling at</li>
<li><em>parse</em>: method that parses and extracts the scraped data, which will be called with the downloaded Response object of each start URL</li>
</ul>


<p>You also need to use the HtmlXpathSelector for working with Xpaths. Visit the Scrapy <a href="http://doc.scrapy.org/en/0.16/">tutorial</a> for more information. The following is the code for the basic spider:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">craigslist_sample.items</span> <span class="kn">import</span> <span class="n">CraigslistSampleItem</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
</span><span class='line'>    <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;craig&quot;</span>
</span><span class='line'>    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;craigslist.org&quot;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;http://sfbay.craigslist.org/search/npo&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span><span class='line'>        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="n">titles</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;//span[@class=&#39;pl&#39;]&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">titles</span> <span class="ow">in</span> <span class="n">titles</span><span class="p">:</span>
</span><span class='line'>            <span class="n">title</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>            <span class="n">link</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>            <span class="k">print</span> <span class="n">title</span><span class="p">,</span> <span class="n">link</span>
</span></code></pre></td></tr></table></div></figure>


<p>Save this in the &ldquo;spiders&rdquo; directory as <em>test.py</em>.</p>

<h2>Test</h2>

<p>Now you are ready for a trial run of the scraper. So, while in the root directory of your Scrapy project, run the following command to output the scraped data to the screen:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>scrapy crawl craig
</span></code></pre></td></tr></table></div></figure>


<p><strong>Dicts:</strong> The <code>Item</code> objects defined above are simply custom dicts. Use the standard dict syntax to return the extracted data inside the Item objects:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">item</span> <span class="o">=</span> <span class="n">CraigslistSampleItem</span><span class="p">()</span>
</span><span class='line'><span class="n">item</span><span class="p">[</span><span class="s">&quot;title&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'><span class="n">item</span><span class="p">[</span><span class="s">&quot;link&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'><span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Release!</h2>

<p>Once complete, the final code looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">craigslist_sample.items</span> <span class="kn">import</span> <span class="n">CraigslistSampleItem</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
</span><span class='line'>    <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;craig&quot;</span>
</span><span class='line'>    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;craigslist.org&quot;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;http://sfbay.craigslist.org/search/npo&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span><span class='line'>        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="n">titles</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&quot;//span[@class=&#39;pl&#39;]&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">items</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">titles</span> <span class="ow">in</span> <span class="n">titles</span><span class="p">:</span>
</span><span class='line'>            <span class="n">item</span> <span class="o">=</span> <span class="n">CraigslistSampleItem</span><span class="p">()</span>
</span><span class='line'>            <span class="n">item</span><span class="p">[</span><span class="s">&quot;title&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>            <span class="n">item</span><span class="p">[</span><span class="s">&quot;link&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>            <span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">items</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Store the data</h2>

<p>The scraped data can now be <a href="http://doc.scrapy.org/en/0.16/topics/feed-exports.html#topics-feed-exports">stored</a> in these formats- JSON, CSV, and XML (among others). Run the following command to save the data in CSV:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>scrapy crawl craig -o items.csv -t csv
</span></code></pre></td></tr></table></div></figure>


<p>You should now have a CSV file in your directory called items.csv full of data:</p>

<p><img src="http://www.backwardsteps.com/uploads/2012-11-05_1411.png" alt="csv" /></p>

<p><em>Although this is relatively simple tutorial, there are still powerful things you can do by just customizing this basic script. Just remember to not overload the server on the website you are crawling. Scrapy allows you to set <a href="https://scrapy.readthedocs.org/en/0.16/topics/settings.html">delays</a> to throttle the crawling speed.</em></p>

<h2>Next time</h2>

<p><em>In my next post I&rsquo;ll show how to use Scrapy to  recursively crawl a site by following links. Until then, you can find the code for this project on <a href="https://github.com/mjhea0/Scrapy-Samples">Github</a>.</em></p>
</div>


  <footer>
    <p class="meta">
      
  



  <span class="byline author vcard">Authored by <span class="fn">
  
    Michael Herman
  
  </span></span>


      




<time class='entry-date' datetime='2012-11-05T14:59:00-07:00'><span class='date'><span class='date-month'>Nov</span> <span class='date-day'>5</span><span class='date-suffix'>th</span>, <span class='date-year'>2012</span></span> <span class='time'>2:59 pm</span></time>
      
      

<span class="categories">
  
    <a class='category' href='/blog/categories/python/'>python</a>
  
</span>


    </p>
    
      <div class="sharing">
<!--   
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://mherman.org/blog/2012/11/05/scraping-web-pages-with-scrapy/" data-via="" data-counturl="http://mherman.org/blog/2012/11/05/scraping-web-pages-with-scrapy/" >Tweet</a>
  
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
   -->
  <br>
  <!-- AddThis Button BEGIN -->
  <div class="addthis_toolbox addthis_default_style addthis_32x32_style">
  <a class="addthis_button_preferred_1"></a>
  <a class="addthis_button_preferred_2"></a>
  <a class="addthis_button_preferred_3"></a>
  <a class="addthis_button_preferred_4"></a>
  <a class="addthis_button_compact"></a>
  <a class="addthis_counter addthis_bubble_style"></a>
  </div>
  <script type="text/javascript">var addthis_config = {"data_track_addressbar":true};</script>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-50e5f1cc35ad077d"></script>
  <!-- AddThis Button END -->
  <br>
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2012/10/19/sentiment-analysis-feelings-not-facts/" title="Previous Post: Sentiment Analysis: Feelings, not Facts">&laquo; Sentiment Analysis: Feelings, not Facts</a>
      
      
        <a class="basic-alignment right" href="/blog/2012/11/08/recursively-scraping-web-pages-with-scrapy/" title="Next Post: Recursively Scraping Web Pages with Scrapy">Recursively Scraping Web Pages with Scrapy &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>


</div>

    </div>
  </div>
  <footer role="contentinfo"><div>
  <span>Copyright &copy; 2016 - Michael Herman</span><br>
  <a href="https://github.com/mjhea0"><i class="fa fa-github-square" style="font-size:2em" aria-hidden="true"></i></a>
  <a href="https://twitter.com/mikeherman"><i class="fa fa-twitter-square" style="font-size:2em" aria-hidden="true"></i></a>
  <a href="http://www.linkedin.com/pub/michael-herman/3b/a94/4"><i class="fa fa-linkedin-square" style="font-size:2em" aria-hidden="true"></i></a>
  <a href="http://www.youtube.com/hermanmu"><i class="fa fa-youtube-square" style="font-size:2em" aria-hidden="true"></i></a>
</div>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'michaelherman';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://mherman.org/blog/2012/11/05/scraping-web-pages-with-scrapy/';
        var disqus_url = 'http://mherman.org/blog/2012/11/05/scraping-web-pages-with-scrapy/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>






<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
