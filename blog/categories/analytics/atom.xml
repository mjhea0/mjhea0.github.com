<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: analytics | Michael Herman]]></title>
  <link href="http://mjhea0.github.com/blog/categories/analytics/atom.xml" rel="self"/>
  <link href="http://mjhea0.github.com/"/>
  <updated>2016-02-10T15:42:37-07:00</updated>
  <id>http://mjhea0.github.com/</id>
  <author>
    <name><![CDATA[Michael Herman]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Cohort Analysis: Data Sourcing with SQL]]></title>
    <link href="http://mjhea0.github.com/blog/2013/07/19/cohort-analysis-data-sourcing-with-sql/"/>
    <updated>2013-07-19T09:48:00-06:00</updated>
    <id>http://mjhea0.github.com/blog/2013/07/19/cohort-analysis-data-sourcing-with-sql</id>
    <content type="html"><![CDATA[<p>As an online business owner, you hope that engagement increases over time, leading to a longer period of retention. This is rarely the case, though. The majority of web applications see a gradual decrease in user engagement, eventually leading to churn. Your goal then is to stretch out the length of engagement as long as possible. The best way to measure this is through cohort analysis.</p>

<p>Put simply, cohort analysis is used to test whether certain groups of users, based on the conversion date, are active and engaging longer (or shorter) than other groups.</p>

<p>The ultimate goal is to test not only how users within each cohort engaged within your app over time, but to also compare and contrast different cohorts with one another. It&#39;s quite often the case that even subtle changes in your application&#39;s feature set will change user engagement, positively or negatively. If the latter, you want to know this as soon as possible to prevent further churn.</p>

<p>That said, let&#39;s look at how to source and cleanse your data in order to begin analysis.</p>

<blockquote>
<p>Please note: I will be using a MySQL database for these examples. The corresponding SQL statements should be simple enough to port over to whatever RDMS you use. Comment if you have questions. You can also look at this <a href="http://www.backwardsteps.com/cohort/cohort_analysis.xlsx">spreadsheet</a> to see how to conduct cohort analysis in Excel.</p>
</blockquote>

<h2>Setup</h2>

<p>If you&#39;d like to follow along, follow these steps to create the table and load the sample data.</p>

<h3>Create the database and tables</h3>

<ol>
<li>Access MySQL via the Shell (or your preferred method):</li>
</ol>

<p><code>sh<br>
$ mysql -u root -p<br>
</code></p>

<ol>
<li>Create a new database, and then select it for use:</li>
</ol>

<p><code>sh<br>
mysql&gt; CREATE DATABASE cohortanalysis;<br>
    mysql&gt; USE cohortanalysis;<br>
</code></p>

<ol>
<li>Use the following commands to create the tables users and events:</li>
</ol>

<p><code>sh<br>
mysql&gt; CREATE TABLE users (id INT(11) PRIMARY KEY NOT NULL, name VARCHAR(40) NOT NULL, date DATETIME NOT NULL);<br>
mysql&gt; CREATE TABLE events (id INT(11) PRIMARY KEY NOT NULL, type VARCHAR(15), user_id INT(11) NOT NULL, date DATETIME NOT NULL, FOREIGN KEY (user_id) REFERENCES users(id));<br>
mysql&gt; exit;<br>
</code></p>

<h3>Load the data</h3>

<p>Download the database file <a href="http://www.backwardsteps.com/cohort/dump.sql">here</a>. Then using the command line, navigate to the file path where the <em>dump.sql</em> file was downloaded. Now, type the following command into your terminal:</p>

<p><code>sh<br>
$ mysql -u root -p cohortanalysis &lt; dump.sql<br>
</code></p>

<p>This command should take a few minutes to run as it loads the data in the database.</p>

<h2>Sourcing Data</h2>

<p>When sourcing your data, itâ€™s important to begin by structuring your SQL queries around user behavior - engagement, in this case.</p>

<p>In this example, we will use a database filled with sample data for a subscription photo-editing application. The database has one table for customers, <em>Users</em>, and another for engagement, <em>Events</em>, among others:</p>

<p><strong>Users:</strong></p>

<p>```sh<br>
mysql&gt; DESCRIBE users;<br>
+-------+-------------+------+-----+---------+-------+<br>
| Field | Type        | Null | Key | Default | Extra |<br>
+-------+-------------+------+-----+---------+-------+<br>
| id    | int(11)     | NO   | PRI | NULL    |       |<br>
| name  | varchar(40) | NO   |     | NULL    |       |<br>
| date  | datetime    | NO   |     | NULL    |       |<br>
+-------+-------------+------+-----+---------+-------+</p>

<p>mysql&gt; SELECT COUNT(*) FROM users;<br>
54541<br>
```</p>

<p><strong>Events:</strong></p>

<p>```sh<br>
mysql&gt; DESCRIBE events;<br>
+---------+-------------+------+-----+---------+-------+<br>
| Field   | Type        | Null | Key | Default | Extra |<br>
+---------+-------------+------+-----+---------+-------+<br>
| id      | int(11)     | NO   | PRI | NULL    |       |<br>
| type    | varchar(15) | YES  |     | NULL    |       |<br>
| user_id | int(11)     | NO   | MUL | NULL    |       |<br>
| date    | datetime    | NO   |     | NULL    |       |<br>
+---------+-------------+------+-----+---------+-------+</p>

<p>mysql&gt; SELECT COUNT(*) FROM events;<br>
101684<br>
```</p>

<blockquote>
<p>As you can tell, there are 54,541 rows of data in the <em>Users</em> table and 101,684 rows in the <em>Events</em> table. The <em>type</em> field in the <em>Events</em> table specifies whether a user has shared (to Twitter or Facebook), commented on, or liked a photo.</p>
</blockquote>

<p>Start by looking at each table individually, beginning with basic queries before moving on to more advanced queries to get a feel for the data you&#39;re working with.</p>

<h3>Monthly Cohorts</h3>

<p>I will be using a new Group Date function to create the cohorts. Follow the installation instructions <a href="http://ankane.github.io/groupdate.sql/">here</a>.</p>

<p>Group users into monthly cohorts, based on sign-up date, and add in the total users for each cohort:</p>

<p>```sh<br>
SELECT GD_MONTH(date, &#39;Greenwich&#39;) AS cohort,<br>
       COUNT(*)<br>
FROM users<br>
GROUP BY cohort;</p>

<p>+---------------------+----------+<br>
| cohort              | COUNT(*) |<br>
+---------------------+----------+<br>
| 2013-02-01 00:00:00 |       48 |<br>
| 2013-03-01 00:00:00 |      338 |<br>
| 2013-04-01 00:00:00 |     1699 |<br>
| 2013-05-01 00:00:00 |     7658 |<br>
| 2013-06-01 00:00:00 |    24716 |<br>
| 2013-07-01 00:00:00 |    20082 |<br>
+---------------------+----------+<br>
```</p>

<blockquote>
<p>Did you notice the time zone (<code>Greenwich</code>)? Try experimenting with other <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">time zones</a> to see how the results change. This is my favorite feature from the Group Date function.</p>
</blockquote>

<p>Like the last query, split the events into cohorts:</p>

<p>```sh<br>
SELECT GD_MONTH(date, &#39;Greenwich&#39;) AS cohort,<br>
       COUNT(*)<br>
FROM events<br>
GROUP BY cohort;</p>

<p>+---------------------+----------+<br>
| cohort              | COUNT(*) |<br>
+---------------------+----------+<br>
| 2013-02-01 00:00:00 |       31 |<br>
| 2013-03-01 00:00:00 |      223 |<br>
| 2013-04-01 00:00:00 |     1351 |<br>
| 2013-05-01 00:00:00 |     6199 |<br>
| 2013-06-01 00:00:00 |    57898 |<br>
| 2013-07-01 00:00:00 |    35982 |<br>
+---------------------+----------+<br>
```</p>

<p>Based on these tables, you can see the total engagement vs. the total users. Right off the bat you can tell that engagement decreases in the latter months? Will this trend continue?</p>

<p><img src="http://content.screencast.com/users/Mike_Extentech/folders/Jing/media/f11068c3-7905-4d7b-8c8e-8037a5905c94/00000212.png" alt="decrease_in_enagement"></p>

<h3>Individual Cohorts</h3>

<p>Now start looking at each individual cohort to see if you can see any outliers or large discrepancies. For simplicity, you can follow this syntax:</p>

<p><code>sh<br>
SELECT<br>
    &lt;action_or_event_date(s)&gt;<br>
FROM<br>
    &lt;table&gt;<br>
WHERE<br>
    user_action = &lt;&#39;some_action_or_event&#39;&gt;<br>
    and user_cohort = &lt;cohort_group&gt;<br>
GROUP BY &lt;action_or_even_date(s)&gt;;<br>
</code></p>

<p>For example:</p>

<p>```sh<br>
SELECT GD<em>MONTH(events.date, &#39;Greenwich&#39;) AS engagement</em>date,<br>
       COUNT(events.id) AS events<br>
FROM users<br>
JOIN events ON users.id = events.user<em>id<br>
WHERE DATE</em>FORMAT(users.date, &#39;%Y/%m&#39;) =&#39;2013/02&#39;<br>
GROUP BY engagement_date;</p>

<p>+---------------------+--------+<br>
| engagement_date     | events |<br>
+---------------------+--------+<br>
| 2013-02-01 00:00:00 |     31 |<br>
| 2013-03-01 00:00:00 |     63 |<br>
| 2013-04-01 00:00:00 |     67 |<br>
| 2013-05-01 00:00:00 |     66 |<br>
| 2013-06-01 00:00:00 |    113 |<br>
| 2013-07-01 00:00:00 |     45 |<br>
+---------------------+--------+<br>
```</p>

<p><img src="http://content.screencast.com/users/Mike_Extentech/folders/Jing/media/38334d7b-39ae-4cf2-b943-35c2e03c7ad7/00000213.png" alt="feb_cohort_engagement"></p>

<p>Continue to add cohorts to learn more about how your users are engaging. See if you can find any trends. Look at comments vs likes vs shares.</p>

<p>In this query, we look at the total percent of twitter shares divided by the total # of engagements:</p>

<p>```sh<br>
SELECT<br>
  (SELECT count(TYPE)<br>
   FROM events<br>
   WHERE TYPE=&quot;twitter share&quot;) AS twitter<em>shares,<br>
  (SELECT count(<em>)<br>
   FROM events) AS total,<br>
  (SELECT count(TYPE)<br>
   FROM events<br>
   WHERE TYPE=&quot;twitter share&quot;)/<br>
  (SELECT count(</em>)<br>
   FROM events)*100 AS percent</em>of_total;</p>

<p>+----------------+--------+------------------+<br>
| twitter<em>shares | total  | percent</em>of_total |<br>
+----------------+--------+------------------+<br>
|          14570 | 101684 |          14.3287 |<br>
+----------------+--------+------------------+<br>
```</p>

<p><img src="http://content.screencast.com/users/Mike_Extentech/folders/Jing/media/9ba9c7d0-e889-4140-9208-3b85f5501244/00000214.png" alt="twitter"></p>

<p>You can even zoom in on individual users:</p>

<p>```sh<br>
SELECT events.id,<br>
       events.type,<br>
       events.date AS enagement<em>date<br>
FROM events<br>
JOIN users ON events.user</em>id = users.id<br>
WHERE users.id = 1<br>
ORDER BY events.type;</p>

<p>+-------+----------------+---------------------+<br>
| id    | type           | enagement_date      |<br>
+-------+----------------+---------------------+<br>
|    22 | comment        | 2013-02-25 05:22:55 |<br>
|     6 | facebook share | 2013-02-13 17:54:59 |<br>
|     1 | like           | 2013-02-10 13:40:03 |<br>
|  6052 | like           | 2013-05-25 16:26:03 |<br>
|  4245 | like           | 2013-05-19 16:04:57 |<br>
|    24 | like           | 2013-02-25 21:13:28 |<br>
|     7 | like           | 2013-02-14 05:20:23 |<br>
|     4 | like           | 2013-02-12 04:10:14 |<br>
|     2 | like           | 2013-02-10 15:35:58 |<br>
|     3 | twitter share  | 2013-02-11 16:40:14 |<br>
| 53353 | twitter share  | 2013-06-28 02:59:44 |<br>
+-------+----------------+---------------------+<br>
```</p>

<h3>Analysis</h3>

<p>Finally, create a chart that shows all the cohorts and their subsequent monthly engagement % for easy comparison. Make sure to normalize the data in this chart (see the ROUND function).</p>

<p>```sh<br>
SELECT results.months,<br>
       results.cohort,<br>
       results.actives AS active<em>users,<br>
       user</em>totals.total AS total<em>users,<br>
       results.actives/user</em>totals.total*100 AS percent<em>active<br>
FROM<br>
  ( SELECT ROUND(DATEDIFF(events.date, users.date)/30.4) AS months,<br>
           DATE</em>FORMAT(events.date, &#39;%Y/%m&#39;) AS MONTH,<br>
           DATE<em>FORMAT(users.date, &#39;%Y/%m&#39;) AS cohort,<br>
           COUNT(DISTINCT users.id) AS actives<br>
   FROM users<br>
   JOIN events ON events.user</em>id = users.id<br>
   GROUP BY cohort,<br>
            months ) AS results<br>
JOIN<br>
  ( SELECT DATE<em>FORMAT(date, &quot;%Y/%m&quot;) AS cohort,<br>
           count(id) AS total<br>
   FROM users<br>
   GROUP BY cohort ) AS user</em>totals ON user<em>totals.cohort = results.cohort<br>
WHERE results.MONTH &lt; DATE</em>FORMAT(NOW(), &#39;%Y/%m&#39;);</p>

<p>+--------+---------+--------------+-------------+----------------+<br>
| months | cohort  | active<em>users | total</em>users | percent_active |<br>
+--------+---------+--------------+-------------+----------------+<br>
|      0 | 2013/02 |           29 |          48 |        60.4167 |<br>
|      1 | 2013/02 |           35 |          48 |        72.9167 |<br>
|      2 | 2013/02 |           38 |          48 |        79.1667 |<br>
|      3 | 2013/02 |           40 |          48 |        83.3333 |<br>
|      0 | 2013/03 |          156 |         338 |        46.1538 |<br>
|      1 | 2013/03 |          251 |         338 |        74.2604 |<br>
|      2 | 2013/03 |          258 |         338 |        76.3314 |<br>
|      3 | 2013/03 |          305 |         338 |        90.2367 |<br>
|      0 | 2013/04 |          888 |        1699 |        52.2660 |<br>
|      1 | 2013/04 |         1290 |        1699 |        75.9270 |<br>
|      0 | 2013/05 |         4454 |        7658 |        58.1614 |<br>
|      1 | 2013/05 |         7004 |        7658 |        91.4599 |<br>
|      2 | 2013/05 |         2157 |        7658 |        28.1666 |<br>
|      0 | 2013/06 |        18612 |       24716 |        75.3034 |<br>
+--------+---------+--------------+-------------+----------------+<br>
```</p>

<p>This is clearly a difficult query, which will require significant modifications based on your own data. In this query we are defining-</p>

<ul>
<li>each cohort by breaking the dates into intervals of 30.4 days (~ one month); and,</li>
<li>the percent of active users (grouped by cohort) by dividing the number of cohorts by total activities for each cohort, then obtaining a percentage by multiplying the results by 100.</li>
</ul>

<p>To make such queries easier, make sure you -</p>

<ol>
<li>Understand your schema/table relationships</li>
<li>Break your query up into smaller, manageable pieces</li>
<li>Conduct quick spot checks beforehand on a portion of the data to ensure that the results you get are correct (yes, add in test driven development for a quick sanity check)</li>
</ol>

<p><img src="http://content.screencast.com/users/Mike_Extentech/folders/Jing/media/c099e4eb-b533-4b2e-930e-d5753effd3cc/00000216.png" alt="final"></p>

<p>Now, even though this is quite difficult, try to come up with the same results in Excel. It&#39;s much harder. Once you become comfortable with SQL - and can break each query down into small bits - it&#39;s actual much easier with SQL.</p>

<h2>Summary</h2>

<p>As you go through your own cohort analysis measuring retention and engagement, think about why your users may stop engaging and leave. For example, is your application useful, perhaps the novelty factor wears off too quickly, or all engagement options have been exhausted.</p>

<p>Remember that even though you may be experiencing a huge amount of growth, engagement may be low - which can be easily be overlooked. This could result in increased churn much sooner. It can&#39;t be said enough that retaining a customer is much cheaper than adding a new customer. Do your best to sustain high engagement over time and locate areas of improvement via cohort analysis.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Charting Best Practices - Proper Data Visualization]]></title>
    <link href="http://mjhea0.github.com/blog/2013/04/28/charting-best-practices-proper-data-visualization/"/>
    <updated>2013-04-28T13:20:00-06:00</updated>
    <id>http://mjhea0.github.com/blog/2013/04/28/charting-best-practices-proper-data-visualization</id>
    <content type="html"><![CDATA[<p>Charting data and determining business progress is an important part of measuring success. From recording financial statistics to webpage visitor tracking, finding the best practices for charting your data is vastly important for your company&#39;s success. Here is a look at five charting best practices for optimal data visualization and analysis.</p>

<h2>Arrange Data in a Clean, Presentable Manner</strong></h2>

<p>To optimize your chart&#39;s readability and presentation, it is vital that you present your data in a clean and easy to read format. Avoid putting too much data on your chart, ensure that your variables are labeled clearly and decisively, and organize your data in a strategic format. For instance, you could have your variables organized from smallest to largest if you are comparing sales figures, or if you are monitoring figures over a length of time, make sure that your chart is in chronological order. Presenting a clean and easily read chart will only improve your ability to analyze your data more effectively.</p>

<h2>Identify the Right Type of Chart for Your Data</h2>

<p>One chart will not meet all of your business needs. It is important to use the chart that will most effectively organize your data and boost your ability to analyze and record data in the future. For example, if you are analyzing revenue totals across a time frame, a line graph may be best for you. Meanwhile, if you are running figures on trends and trying to determine a percentage breakdown for popular opinion a pie chart may be most effective. There are a variety of different charts you can use. To maximize your research&#39;s effectiveness, it is vital that you select the right type of chart.</p>

<h2>Determine What Vital Information Should Be Captured in Your Chart</h2>

<p>Most businesses run many reports that they obtain data from. Although you may have to keep track of a variety of data, it is important to keep your reporting clean and charts highly visual and readable. Determine what vital information belongs on your chart. Organization is key to maintaining clean charts and allowing you to effectively analyze data in the future. Keep only what you need on your chart, you can always create separate ones for different metrics (and you should!). On a similar note, it is important to remove unnecessary data from your chart. Keep it clean and concise to allow users to easily read the data they need, without having to filter or delete fields at a later time.</p>

<h2>Create Charts with Vibrant Color Coding to Assist in Data Visualization</h2>

<p>Creating charts with vibrant colors and bolded fonts allows users to easily and effectively analyze your chart in less time. It has also been proven that vibrant charts and presentations keep the users more engaged than boring, flat data charts and slides. Engage your audience with vivid charts that read easy and are cleanly presented.</p>

<h2>Keep Your Language Simple</h2>

<p>While you may be aiming to impress your audience with impressive statistics and a thorough presentation, it should be said that your chart should include language that is easy to understand. Your chart is no place for adverbs or expressive language. Label your chart clearly and simply, making it easy to read and view.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understand your Support System Better with Sentiment Analysis]]></title>
    <link href="http://mjhea0.github.com/blog/2013/01/09/understand-your-support-system-better-with-sentiment-analysis/"/>
    <updated>2013-01-09T09:13:00-07:00</updated>
    <id>http://mjhea0.github.com/blog/2013/01/09/understand-your-support-system-better-with-sentiment-analysis</id>
    <content type="html"><![CDATA[<p>Thereâ€™s more to evaluating success than monitoring your bottom line. While analyzing your support system on a macro level helps to ensure your costs are going down and earnings are rising, taking a micro approach to your business gives you a thorough appreciation of your businessâ€™ performance. Sentiment analysis helps you to clearly see whether your business practices are leading to higher customer satisfaction, or if youâ€™re on the verge of running clients away.</p>

<p>Not all support measures pay off in the long run. Unfortunately, analyzing them for effectiveness takes more than a look at the ledger book. Profits and expenses have a way of missing the bigger picture, so it makes sense to invest in methods you can use to keep track of your companyâ€™s reputation.</p>

<h2>Sentiment Analysis, defined</h2>

<p>Simply put, sentiment analysis is a way of determining peopleâ€™s opinions based on what they write. Computer programs assess written statements having to do with your company, and determine whether the authors like you or not. Obviously, depending on the program used, your results will be more or less accurate.</p>

<p>In addition, you need to have easy access to many forms of communication related to your company.</p>

<h2>Zapier</h2>

<p>Web application automation hub <a href="https://zapier.com/blog/2012/12/11/sentiment-analysis-humans/">Zapier</a> is an excellent example of a service that is easy to use, efficient at delivering multiple types of entries involving support and is affordable for most businesses, regardless of size. With it, you can tap into over 150 web applications used for mixing and matching web-based programs to seamlessly run your company online. Now, you can take advantage of sentiment analysis through a Zapier-friendly, highly-accurate API called Semantria.</p>

<p>With the help of this relatively new API, you can analyze any text that relates to your companyâ€™s support system (such as Zendesk or Desk.com, etc.). Twitter posts, for example, can help you gauge whether people are tweeting about your company and programs in a good or bad way. Chat room logs, help desk tickets and the like can provide a tremendous amount of feedback on your business.</p>

<p>Once analyzed, the results can be delivered back to you in a number of ways. Google Docs is a popular option because itâ€™s easily integrated with so many programs, and because itâ€™s free. Both Zapier and Semantria are affordable too. Free trials and a variety of payment options allow businesses big and small to get a taste of sentiment analysis without spending a bundle. You can also use these affordable options to analyze the effectiveness of your support system changes.</p>

<p><br></p>

<p>Want to get up to speed quickly on conducting your own Sentiment Anlysis?</p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/adIvt_luO1o "></iframe></div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Integration of Content Creation Leads Google Towards the Slippery Slope of Monopolies]]></title>
    <link href="http://mjhea0.github.com/blog/2012/11/18/integration-of-content-creation-leads-google-towards-the-slippery-slope-of-monopolies/"/>
    <updated>2012-11-18T19:19:00-07:00</updated>
    <id>http://mjhea0.github.com/blog/2012/11/18/integration-of-content-creation-leads-google-towards-the-slippery-slope-of-monopolies</id>
    <content type="html"><![CDATA[<p>How are monopolies created? It seems weird that monopolies can still exist, but they are alive and well despite laws and regulations . With tech companies, it becomes surprisingly easy as they develop or acquire exclusive start-ups, technologies and patents. However, this normally means just temporary dominance in a certain industry until competitors catch up. A true monopoly like those of the 19th and 20th centuries arise when one company dominates every aspect of an industry. The company can then game the market forcing customers to buy their services at that the price and conditions they set. The company benefits from coordinating its services and forces out competitors that specialize or have fewer resources. In short, the company becomes the only game in town. Google faces this daunting boundary as it starts to acquire content producing companies and websites. Is it right for a search engine to also provide content when people rely on it to find content from the top providers?</p>

<h2>Google and Content Creation Not New</h2>

<p>While recent acquisitions raise the ire of consumer advocates, Google was on this path for a while. The biggest acquisition would be the purchase of the popular video website YouTube. YouTube is a veritable geyser of content creation by both professional companies and private users. Google for the time being, doesn&#39;t really cross lines because YouTube is more of a platform for creative content than a direct source. However, certain practices on its search engine for YouTube point to possible conflicts of interest that signal a monopoly forming. For example, video results for the search engine put YouTube results before those of other media websites like Daily Motion or Veoh. This is a major problem for market competition when looking at how YouTube benefits from its integration with Google&#39;s multi-billion dollar infrastructure. Is it fair for its competitors for YouTube to have such an advantage?</p>

<h2>From Content Finder To Content Producer</h2>

<p>The line gets more blurry as Google looks to provide its own native content for YouTube and other websites. Google recently purchased Next New Networks, a web TV production company. The company has a reputation for creating original content for online viewing producing several popular web shows and shorts. With the backing of a major company like Google and the wide reach of the YouTube platform, the company could soon compete with traditional media outlets like ABC and NBC Universal. The problem lies in how this conflicts with Google&#39;s role as a search engine. Google could game search results to put its shows over other companies&#39; products instead of relying on actual user response and interest. The worst part is that users could only detect something wrong after a significant period of time.</p>

<h2>Why Acquiring Content Providers Leads To Monopoly Of Search Results</h2>

<p>YouTube is a general platform. Even if Google provides content, the majority comes from other sources, even competitors like Microsoft and Apple. Google&#39;s recent acquisition of Zagat and Frommer&#39;s shows what happens when the company directly provides content for the search engines. Zagat and Frommer&#39;s are sites that provide online travel guides and information. Its competitors are websites like Lonely Planet. As a subsidiary of Google, there are several ways the company can benefit on Google&#39;s search engine. First, the site can get free sponsored adds and searches when users make relevant searches. This is the same as automatically getting to the top of the Google pages. This is unfair to competitors who have to climb the rankings the hard way through building up a following through good content and costly marketing. In essence Google could use its unfair advantage to dominate or acquire competitors in the online travel guide business. Google becomes more and more like the famous political cartoon of Standard Oil. It is an octopus with its tentacles in various web related sectors and industries using its collective advantages to push out legitimate competitors.</p>

<p>The issue is serious, and an interesting indicator of growing awareness about it was its use as a plot point in an episode of the popular Law Procedural/ Drama, The Good Wife. In a recent episode, two college students create a revolutionary voice software that a major search engine sabotages by altering the search results. The reason was they refused to sell their idea and the company buys their competitor and promotes them instead. The show raised the problem of providing direct legal evidence of the crime especially when the plaintiffs were bought out with jobs. Hopefully Google hasn&#39;t reached that point yet, but the temptation to follow such actions eventually become irresistible.</p>

<h2>Customers May Act As Check</h2>

<p>Google is unique because its revenue <a href="http://venturebeat.com/2012/01/29/google-advertising/">comes</a> indirectly from advertising and depends on the users of its search engine and other products who see its ads. Its services are popular because customers rely on the impartiality of its algorithm to provide the most relevant content. If customers see Google tilting the board in their own favor, it could drive users to alternative search engines such as DuckDuckGo  and Bing. To avoid such scenarios Google has to follow the rules it now uses with YouTube allowing many content providers to use its new content services as a platform. This way it can maintain the separation it needs as a search engine. If not, regulators will step in and limit their actions in more detrimental ways.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Benefits of Performing a Cohort Analysis in Determining Engagement Over Time]]></title>
    <link href="http://mjhea0.github.com/blog/2012/11/16/the-benefits-of-performing-a-cohort-analysis-in-determining-engagement-over-time/"/>
    <updated>2012-11-16T18:57:00-07:00</updated>
    <id>http://mjhea0.github.com/blog/2012/11/16/the-benefits-of-performing-a-cohort-analysis-in-determining-engagement-over-time</id>
    <content type="html"><![CDATA[<p>A cohort analysis is a type of study which is mainly conducted by observation over a period of time. It works by analyzing a given group of individuals who have a trait or experience in common, within a given time. It is a great tool used in retaining customers and it is especially useful for business owners who have websites.</p>

<p>Since more visitors to the site generally translate into more business, it is important to retain these clients and monitor the regularity with which they come back.</p>

<p>The term engagement is used to describe the time that is spent accessing the product. It denotes frequency and it is essential to measure this level and analyze it as it relates to certain intervals.</p>

<p><strong>Examples:</strong></p>

<ol>
<li> Time to first purchase or engagement (e.g. follow, post, signup)</li>
<li> % activating in first day, week, month, etc. (B2C vs. B2B)</li>
<li> Repeat rate, 2x%2B repeat rate, 3x%2B repeat rate, etc.</li>
<li> How does first purchase (or engagement proxy) impact future revenue/engagement?</li>
<li> Email Opt-out behavior or member churn</li>
</ol>

<h2><strong>Benefits of Conducting an Effective Cohort Analysis</strong></h2>

<p><strong>Accuracy</strong></p>

<p>Performing a cohort analysis is a highly effective method of study as it helps to separate the clients into cohorts. Thus, individuals who joined the site during a particular period are grouped together e.g. the March cohort, the April cohort and so on. This way, the analysis of their engagement and how it has changed over time, is unaffected by the individuals in other groups, thus keeping the groups completely independent of one another; and facilitating a more accurate study.</p>

<p><strong>Providing a clear distinction between Growth and Engagement</strong></p>

<p>Separating the clients into cohorts is also effective in clearly defining a difference between growth metrics and engagement metrics. These two measurements can sometimes be confused with each other as growth is the successful addition of clients who use one&#39;s product or service. Generally, added numbers automatically increase the overall engagement but it may only be the new clients who access the website, and will probably cease to do so after a while.</p>

<p>Performing a cohort analysis therefore helps one to make a distinction between the two and as a result, the rate of growth, which may be high, does not hide any issues that may need to be addressed as far as engagement or participation and interaction with the product, is concerned. These issues are therefore identified and effectively dealt with in order to facilitate higher retention.</p>

<p><strong>Effective Comparison of data between Cohorts</strong></p>

<p>A cohort analysis also helps one to compare the results between two or more groups. For instance, if the April cohort is more engaged in the product than the March cohort, an analysis may be required on any changes that may have occurred between the two months. In addition, a further analysis may be performed on the groups themselves to see whether the product is possibly appealing to a particular set of people and not another.</p>

<h2><strong>Studying a Wide Range of Data</strong></h2>

<p>By performing a cohort analysis, it is possible to effectively study data across the <a href="http://500hats.typepad.com/500blogs/2007/09/startup-metrics.html">five major metrics</a> (AARRR) for start-ups:</p>

<ul>
<li>  <em>Acquisition:</em> the cost of acquiring first-time users</li>
<li>  <em>Activation:</em> the speed at which clients are becoming active, including events, in addition to various actions on the website</li>
<li>  <em>Retention:</em> the ability to retain a client who is engaged in the service - they make purchases and are basically a source of recurring revenue</li>
<li>  <em>Referral:</em> rate at which people are inviting others to the site, as well as the rate at which the invitees yield to the invitations and actually visit the site</li>
<li>  <em>Revenue:</em> first point of purchase as far as the client is concerned.</li>
</ul>

<p>Each of these metrics is important and it is therefore essential that an eye be kept on them to recognize when changes need to be made. A cohort analysis enables one to do just that, without using multiple tools.</p>

<h2>Facilitating speedy Decision Making</h2>

<p>A cohort analysis also helps in identifying times when engagement in the site drops. Since it is a study that takes time into consideration, decisions can be made fast in an effort to rectify the problem areas that may have resulted in the drop. By factoring-in time, there is a clear temporal sequence when analyzing the relationship between first contact with the website, and consequent results.</p>

<h2>Video</h2>

<blockquote>
<p>Check out the <a href="http://www.youtube.com/watch?v=2QZQolcLo6M">video</a>!</p>
</blockquote>

<p>The video illustrates how a cohort analysis is performed. In my opinion Excel is the best tool to use for cohort analysis as it&#39;s much easier than say Mixpanel or Kissmetrics - plus you get your hands dirty and (hopefully) gain an understanding of your data. Although, I really do like <a href="http://blog.rjmetrics.com/see-what-drives-repeat-business-in-your-rjmetrics-online-dashboard/">RJMetrics</a> for cohort analysis as well.</p>

<p>Dummy data has been used on the premise that the business has been operating for an entire year.</p>

<p>That said the data has been generated from real data, which I obtained using <a href="https://zapier.com/">Zapier</a>. With Zapier, you can easily source data from hundreds of locations like <a href="https://zapier.com/blog/2012/09/18/making-salesforce-work-with-your-favorite-apps/">Salesforce</a>, ZenDesk, Zoho, MySQL, and <a href="https://zapier.com/blog/2012/07/01/shopify-integrations-boost-retention-increase-upsales-and-provide-killer-customer-support/">Shopify</a>.</p>

<p>The video begins with showing you how to divide the users of a service into cohorts, based on the time that they first subscribed for the services. The retention rate has also been included. These values are obtained by dividing the number of users, who are still subscribing after a particular month, by the total number of users who started in each category. The average retention rate is therefore obtained by calculating the average across the cohort.</p>
]]></content>
  </entry>
  
</feed>
