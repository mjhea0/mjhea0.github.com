
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Michael Herman</title>
  <meta name="author" content="Michael Herman">

  
  <meta name="description" content="This is a simple tutorial on how to write a crawler using Scrapy (BaseSpider) to scrape and parse Craigslist Nonprofit jobs in San Francisco and &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mjhea0.github.com/blog/page/18">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Michael Herman" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37074204-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner">
</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:mjhea0.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2012/11/05/scraping-web-pages-with-scrapy/">Scraping Web Pages With Scrapy</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2012-11-05T14:59:00-07:00" pubdate data-updated="true">Nov 5<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>This is a simple tutorial on how to write a crawler using Scrapy (BaseSpider) to scrape and parse Craigslist Nonprofit jobs in San Francisco and store the data to a CSV file. If you don&#39;t have any experience with Scrapy, start by reading this <a href="http://doc.scrapy.org/en/latest/intro/tutorial.html">tutorial</a>. Also, I assume that you are familiar with Xpath; if not, please read the Xpath basic <a href="http://w3schools.com/xpath/">tutorial</a> on w3schools. Enjoy!</em></p>

<p><strong>Installation:</strong> Start by <a href="http://scrapy.org/">downloading</a> and installing Scrapy and all its dependencies. Refer to this <a href="http://www.youtube.com/watch?v=eEK2kmmvIdw">video</a>, if you need help.</p>

<p><strong>Create Project:</strong> Once installed, open your terminal and create a Scrapy project by navigating to the directory you&#39;d like to store your project in and then running the following command: </p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">scrapy</span> <span class="n">startproject</span> <span class="n">craigslist_sample</span>
</span></code></pre></td></tr></table></div></figure>

<p><strong>Item Class:</strong> Open the items.py within the ~craigslist_sample\craigslist_sample directory. Edit the items.py file to define the fields that you want contained with the Item. Since we want the post title and subsequent URL, the Item class looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Define here the models for your scraped items</span>
</span><span class='line'>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span><span class="p">,</span> <span class="n">Field</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">CraigslistSampleItem</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
</span><span class='line'>  <span class="n">title</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span><span class='line'>  <span class="n">link</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>

<p><strong>The Spider:</strong> The spider defines the initial URL (http://sfbay.craigslist.org/npo/), how to follow links/pagination (if necessary), and how to extract and parse the fields defined above. The spider must define these attributes:</p>

<ul>
<li><em>name</em>: the spider&#39;s unique identifier</li>
<li><em>start_urls</em>: URLs the spider begins crawling at</li>
<li><em>parse</em>: method that parses and extracts the scraped data, which will be called with the downloaded Response object of each start URL</li>
</ul>

<p>You also need to use the HtmlXpathSelector for working with Xpaths. Visit the Scrapy <a href="http://doc.scrapy.org/en/0.16/">tutorial</a> for more information. The following is the code for the basic spider:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">craigslist_sample.items</span> <span class="kn">import</span> <span class="n">CraigslistSampleItem</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
</span><span class='line'>    <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;craig&quot;</span>
</span><span class='line'>    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;craigslist.org&quot;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;http://sfbay.craigslist.org/npo/&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span><span class='line'>        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="n">titles</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;//span[@class=&#39;pl&#39;]&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">titles</span> <span class="ow">in</span> <span class="n">titles</span><span class="p">:</span>
</span><span class='line'>            <span class="n">title</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>            <span class="n">link</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>            <span class="k">print</span> <span class="n">title</span><span class="p">,</span> <span class="n">link</span>
</span></code></pre></td></tr></table></div></figure>

<p>Save this in the ~\craigslist<em>sample\craigslist\</em>sample\spiders directory as test.py.</p>

<p><strong>Trial:</strong> Now you are ready for a trial run of the scraper. So, while in the root directory of your Scrapy project, run the following command to output the scraped data to the screen:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>scrapy crawl craig
</span></code></pre></td></tr></table></div></figure>

<p><strong>Dicts:</strong> The Item objects defined above are simply custom dicts. Use the standard dict syntax to return the extracted data inside the Item objects:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">item</span> <span class="o">=</span> <span class="n">CraigslistSampleItem</span><span class="p">()</span>
</span><span class='line'><span class="n">item</span> <span class="p">[</span><span class="s">&quot;title&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'><span class="n">item</span> <span class="p">[</span><span class="s">&quot;link&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>

<p><strong>Release:</strong> Once complete, the final code looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">craigslist_sample.items</span> <span class="kn">import</span> <span class="n">CraigslistSampleItem</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
</span><span class='line'>  <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;craig&quot;</span>
</span><span class='line'>  <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;craigslist.org&quot;</span><span class="p">]</span>
</span><span class='line'>  <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;http://sfbay.craigslist.org/npo/&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span><span class='line'>      <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>      <span class="n">titles</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;//span[@class=&#39;pl&#39;]&quot;</span><span class="p">)</span>
</span><span class='line'>      <span class="n">items</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>      <span class="k">for</span> <span class="n">titles</span> <span class="ow">in</span> <span class="n">titles</span><span class="p">:</span>
</span><span class='line'>          <span class="n">item</span> <span class="o">=</span> <span class="n">CraigslistSampleItem</span><span class="p">()</span>
</span><span class='line'>          <span class="n">item</span> <span class="p">[</span><span class="s">&quot;title&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>          <span class="n">item</span> <span class="p">[</span><span class="s">&quot;link&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;a/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>          <span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">items</span>
</span></code></pre></td></tr></table></div></figure>

<p>*<em>Store the data: *</em>The scraped data can now be <a href="http://doc.scrapy.org/en/0.16/topics/feed-exports.html#topics-feed-exports">stored</a> in these formats- JSON, CSV, and XML (among others). Run the following command to save the data in CSV:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>scrapy crawl craig -o items.csv -t csv
</span></code></pre></td></tr></table></div></figure>python

You should now have a CSV file in your directory called items.csv full of data:

![](http://www.backwardsteps.com/uploads/2012-11-05_1411.png)

*Although this is relatively simple tutorial, there are still powerful things you can do by just customizing this basic script. Just remember to not overload the server on the website you are crawling. Scrapy allows you to set [delays](https://scrapy.readthedocs.org/en/latest/topics/settings.html?highlight=delay#download-delay) to throttle the crawling speed.*


***

<div class="embed-video-container"><iframe src="http://www.youtube.com/embed/1EFnX1UkXVU "></iframe></div>

<hr>

<p><em>In my next post I&#39;ll show how to use Scrapy to  recursively crawl a site by following links. Until then, you can find the code for this project on <a href="https://github.com/mjhea0/Scrapy-Samples">Github</a>.</em></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2012/10/19/sentiment-analysis-feelings-not-facts/">Sentiment Analysis: Feelings, Not Facts</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2012-10-19T14:32:00-06:00" pubdate data-updated="true">Oct 19<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Sentiment analysis is a process, which gathers the latest input from a human source or several human sources and uses it to determine the general opinion of a person, place or thing. For example, the old-fashioned comment boxes and comment cards is a form of sentiment analysis. Often called opinion gathering, sentiment analysis can be generated from various technological sources, like Twitter or Facebook. Like the old fashioned comment box, sentiment analysis can help owners or managers find the strengths and weaknesses of a business.</p>

<p>Sentiment analysis, using modern social media platforms, benefits your business by giving a true grasp of what the customers think about the business. Customers will say exactly what they think as social media has a cloak of anonymity associated with it. They often will say names and help you pinpoint the best and worst of your employees. Sentiment analysis is important to your business as it aids in evaluation and discovery of the need for new products, services, and improvements.  For example, if a reoccurring tweet on twitter addresses the awful paint on the wall, the business can address the ambiance issue. In addition, the international nature of social media ensures that plenty of people will read the sentiment and adjust their behavior accordingly.</p>

<p>A single opinion posted on the web can damage a business&#39;s image quickly. And finding opinions on the web takes only a rudimentary knowledge of search engine. Think of the social media as technical, international version of word-of-mouth. A single opinion can spread like gasoline and a match. Making sentiment analysis of social platforms part of the business&#39;s regular routine will help the person in charge limit the damage.</p>

<p>On the other hand, a good comment on social media can bring in more customers.  Performing sentiment analysis on twitter and other social media platforms let the business owner market based on the positive sentiment. After all, if one person likes something, such a certain product or customer service, then others will like it, too.</p>

<p>That&#39;s why sentiment analysis is important to businesses. It allows business owners or managers to keep their finger on the pulse of their business. The most successful businesses know that customers are the life blood of the business and their opinion matters. Gone are the days of hardwood boxes and paper forms, but sentiment analysis is still just as important to the success of a business. Business owners and managers use it to improve every aspect of their business. How would you use sentiment analysis to improve your business?</p>

<hr>

<div class="embed-video-container"><iframe src="http://www.youtube.com/embed/YmOYrozqCps "></iframe></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2012/10/06/differentiating-between-bounce-rates/">Differentiating Between Bounce Rates</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2012-10-06T14:09:00-06:00" pubdate data-updated="true">Oct 6<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Understanding your site&#39;s bounce rate is essential to your online presence success.</p>

<p>A low bounce rate signifies ineffectiveness and lost revenue. A high bounce rate signifies your visitors are meeting your objectives and taking action.</p>

<p>Bounce rate is defined as percentage of visitors who come onto your site and leave your page, or site, after not clicking anywhere else on your site. It is a metric tool that measures the quality of your web pages.</p>

<p>You must understand that bounce rate and exit rate are not the same. Bounce rate is the percentage of people who visit any page of your site without going further. They click off within seconds, or even a split second. Exit rate, on the other hand, is when people leave your site after staying for more than a few seconds. Every visitor needs to exit your website, not every one needs to bounce off.</p>

<p>Before you can differentiate between different types of bounce rates, you must analyze different traffic sources. You need to determine where your traffic comes from and what their bounce rates are. If your incoming traffic sources have poor bounce rates, it will reflect poorly on your rate. The largest amount of converting traffic sources include search engine traffics, email marketing campaigns and affiliate campaigns.</p>

<p><strong>When analyzing your incoming traffic, forget about unqualified sources such as social media sites, unknown referrer sites and random directory sites.</strong></p>

<p>Google Analytics is a wonderful tool for analyzing bounce rates. Combining the data obtained from Google Analytics with the spreadsheet capabilities of Excel 2013 will highlight which pages have increased bounce rates.</p>

<p><strong>Increased bounce rates occur for a variety of reasons including outdated and stale web content, ineffective ad-words and your competition changing tactics. Tactics include enhancing a marketing campaign, implementing effective ad-words, updating web content and reducing prices.</strong></p>

<p>The effectiveness of your keywords, and phrases, will affect your bounce rate. Effective keywords, which provide visitors with information they are looking for, will result in lower bounce rates. On the other hand, if your website uses ineffective keywords, your visitor will leave as soon as they realize your site is not appropriate. Nothing is more frustrating in the Internet world than typing in a keyword or keyword phrase and being taken to a website that has nothing to do with what is being searched for.</p>

<p><strong>Analyze the keywords on every page of your website with a website analyzer tool like Google Analytics. Make adjustments as needed.</strong></p>

<p>Does your landing page contain action-oriented language that stimulates interest? Is the information specific and user-friendly? Is content organized optimally? Then, your bounce rate will be lower since visitors want to stay on your page. They will also be more inclined to view other pages on your site.</p>

<p>On the other hand, if your landing page is generalized and/or leads your visitor on a clicking search, your bounce rate will be high. Your landing page will not meet your visitor&#39;s expectations and they will quickly leave.</p>

<p><strong>Bounce rates directly impacts your ROI and revenues. They can point out which information/pages need revisions, increase your conversion rate, highlight where you are wasting your money and help you focus in on your objectives. Are you using them to your advantage?</strong></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/19/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/17/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/04/26/testing-angularjs-with-protractor-and-karma-part-2/">Testing AngularJS with Protractor and Karma - part 2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/04/09/testing-angularjs-with-protractor-and-karma-part-1/">Testing AngularJS with Protractor and Karma - part 1</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/06/node-with-docker-continuous-integration-and-delivery/">Node with Docker - continuous integration and delivery</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/12/postgresql-and-nodejs/">PostgreSQL and NodeJS</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/05/sublime-text-for-web-developers/">Sublime Text for Web Developers</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/analytics/'>analytics (8)</a></li>
<li class='category'><a href='/blog/categories/angular/'>angular (5)</a></li>
<li class='category'><a href='/blog/categories/crowdfunding/'>crowdfunding (1)</a></li>
<li class='category'><a href='/blog/categories/docker/'>docker (1)</a></li>
<li class='category'><a href='/blog/categories/excel/'>excel (3)</a></li>
<li class='category'><a href='/blog/categories/finance/'>finance (2)</a></li>
<li class='category'><a href='/blog/categories/frontend/'>frontend (1)</a></li>
<li class='category'><a href='/blog/categories/git/'>git (1)</a></li>
<li class='category'><a href='/blog/categories/github/'>github (1)</a></li>
<li class='category'><a href='/blog/categories/meteor/'>meteor (1)</a></li>
<li class='category'><a href='/blog/categories/news/'>news (2)</a></li>
<li class='category'><a href='/blog/categories/node/'>node (12)</a></li>
<li class='category'><a href='/blog/categories/python/'>python (11)</a></li>
<li class='category'><a href='/blog/categories/ruby/'>ruby (3)</a></li>
<li class='category'><a href='/blog/categories/startups/'>startups (3)</a></li>
<li class='category'><a href='/blog/categories/sublime/'>sublime (2)</a></li>

  </ul>
</section><section>
  <h1>About Me</h1>
  <p>A little something about me.</p>
</section>






  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Michael Herman <br/>
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a>, customized with <a href="https://github.com/mjhea0/whiterspace">whiterspace</a>.</span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'michaelherman';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
